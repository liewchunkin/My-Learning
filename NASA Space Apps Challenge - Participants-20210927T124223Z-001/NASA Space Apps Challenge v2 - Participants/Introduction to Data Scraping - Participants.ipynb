{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting up Chrome Driver for Selenium\n",
    "\n",
    "chrome://version/\n",
    "\n",
    "\n",
    "https://chromedriver.chromium.org/downloads\n",
    "\n",
    "### Inspecting website using Developer Tools\n",
    "\n",
    "Developer tools can help you understand the structure of a website. All modern browsers come with developer tools installed. In this section, youâ€™ll see how to work with the developer tools in Chrome. The process will be very similar to other modern browsers.\n",
    "\n",
    "\n",
    "http://books.toscrape.com/index.html\n",
    "\n",
    "* Mac: Cmd+Alt+I\n",
    "* Windows/Linux: Ctrl+Shift+I\n",
    "    \n",
    "* All: F12\n",
    "\n",
    "\n",
    "HTML Markup Language\n",
    "CSS Styling Language\n",
    "JS Programming Language\n",
    "\n",
    "### Follow the rules for scrapers and bots\n",
    "Each site usually has a robots.txt on the root of their domain. This is where the website owner explicitly states what bots are allowed to do on their site. Simply go to example.com/robots.txt and you should find a text file.\n",
    "\n",
    "\n",
    "* https://www.facebook.com/robots.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "URL = \"http://books.toscrape.com/index.html\"\n",
    "page = requests.get(URL)\n",
    "\n",
    "#print(page.text)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. import the requests library.\n",
    "2. specify the URL you want to scrape.\n",
    "3. send a HTTP request to the specified URL and save the response from server in a response object called page\n",
    "\n",
    "`page.text` would be preferred for textual responses, such as an HTML or XML document, and `page.content` would be preferred for \"binary\" filetypes, such as an image or PDF file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import web grabbing client and\n",
    "# HTML parser\n",
    "# urllib is a native python library that is already available to you.\n",
    "from urllib.request import urlopen\n",
    "\n",
    "url = 'http://books.toscrape.com/index.html'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# grab website and store in variable client\n",
    "client = urlopen(url)\n",
    "# read and close HTML\n",
    "page_html = client.read()\n",
    "client.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BeautifulSoup is a tool for HTML parsing but we will need a web client to grab something from the internet. \n",
    "\n",
    "**html.parser** - BeautifulSoup(markup, \"html.parser\")\n",
    "\n",
    "* Advantages: Decent speed, Lenient (as of Python 2.7.3 and 3.2.)\n",
    "\n",
    "* Disadvantages: Not very lenient (before Python 2.7.3 or 3.2.2)\n",
    "\n",
    "**lxml** - BeautifulSoup(markup, \"lxml\")\n",
    "\n",
    "* Advantages: Very fast, Lenient\n",
    "\n",
    "* Disadvantages: External C dependency\n",
    "\n",
    "**html5lib** - BeautifulSoup(markup, \"html5lib\")\n",
    "\n",
    "* Advantages: Extremely lenient, Parses pages the same way a web browser does, Creates valid HTML5\n",
    "\n",
    "* Disadvantages: Very slow, External Python dependenc\n",
    "\n",
    "A single book and its information are contained under the `<li>` tag. \n",
    "\n",
    "The findAll() function looks for all the li tags with class(can be ID if its ID) named `col-xs-6 col-sm-4 col-md-3 col-lg-3` and stores it in the variable bookshelf."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup as BS\n",
    "\n",
    "# call BeautifulSoup for parsing\n",
    "page_soup = BS(page_html, \"html.parser\")\n",
    "# grabs all the products under list tag\n",
    "bookshelf = page_soup.findAll(\"li\", {\"class\": \"col-xs-6 col-sm-4 col-md-3 col-lg-3\"})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It will store all information about that `<li>` class which are the books. You can see in the picture above, each `<li>` tag and class : `col-xs-6 col-sm-4 col-md-3 col-lg-3` represents one book.\n",
    "Now that we have all our books, we need to select which particular information we must extract from each book and that is Title and Price. \n",
    " \n",
    "The title of each book is under `<h3>` tag which is under the `<a>` tag with `title`\n",
    "\n",
    "The price is under `<p>` tag in class : `price_color` so we use findAll()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# create csv file of all products\n",
    "filename = (\"Books.csv\")\n",
    "f = open(filename, \"w\")\n",
    "\n",
    "headers = \"Book title, Price, Availability\\n\"\n",
    "f.write(headers)\n",
    "\n",
    "for books in bookshelf:\n",
    "\n",
    "    # collect title of all books\n",
    "    book_title = books.h3.a[\"title\"]\n",
    "\n",
    "    # collect book price of all books\n",
    "    book_price = books.findAll(\"p\", {\"class\": \"price_color\"})\n",
    "    price = book_price[0].text.strip()\n",
    "    \n",
    "    book_availability = books.findAll(\"p\", {\"class\": \"instock availability\"})[0].text.strip()\n",
    "\n",
    "    print(\"Title of book: \" + book_title)\n",
    "    print(\"Price of book: \" + price)\n",
    "    print(\"Book availability: \"+ book_availability)\n",
    "\n",
    "    f.write(book_title + \",\" + price+ \",\" + book_availability+\"\\n\")\n",
    "\n",
    "f.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "url = 'https://books.toscrape.com/'\n",
    "driver = webdriver.Chrome()\n",
    "driver.get(url)\n",
    "print(driver.title)\n",
    "def get_books_info():\n",
    "    data = []\n",
    "    container = driver.find_element_by_xpath('/html/body/div/div/div/div/section/div[2]/ol')\n",
    "    \n",
    "    print(type(container))\n",
    "    \n",
    "    titles = container.find_elements_by_tag_name('a')\n",
    "    for title in titles:\n",
    "        print(title.text)\n",
    "        \n",
    "    prices = container.find_elements_by_class_name('price_color')\n",
    "    for price in prices:\n",
    "        print(price.text)\n",
    "        \n",
    "\n",
    "    next_page = driver.find_element_by_link_text('next')\n",
    "    next_page.click()\n",
    "\n",
    "\n",
    "for x in range(5):\n",
    "    get_books_info()\n",
    "driver.quit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install spacytextblob\n",
    "#!pip install textblob\n",
    "from textblob import TextBlob\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_lyrics(url):\n",
    "    page = requests.get(url)\n",
    "    html = BeautifulSoup(page.text, \"html.parser\")\n",
    "    lyrics = html.find(\"pre\", class_=\"lyric-body\").get_text()\n",
    "    print(url)\n",
    "    #print(lyrics)\n",
    "    return lyrics.replace(\"\\n\",\" \")\n",
    "\n",
    "\n",
    "links = ['https://www.lyrics.com/lyric/36863481/Justin+Bieber/Yummy',\n",
    "     'https://www.lyrics.com/lyric/35362456/Ed+Sheeran/Castle+on+the+Hill',\n",
    "     'https://www.lyrics.com/lyric/35342586/Taylor+Swift/22',\n",
    "     'https://www.lyrics.com/lyric/36147543/Kygo/Happy+Now',\n",
    "     'https://www.lyrics.com/sublyric/58125/Lauv/Superhero',\n",
    "     'https://www.lyrics.com/lyric/30514737/Fix+You',\n",
    "     'https://www.lyrics.com/lyric/32981724/One+Direction/Perfect',\n",
    "     'https://www.lyrics.com/lyric/36489666/Bahari/Crashing',\n",
    "     'https://www.lyrics.com/lyric/33787626/ROZES/Matches',\n",
    "     'https://www.lyrics.com/lyric/36341880/Maroon+5/She+Will+Be+Loved',\n",
    "     'https://www.lyrics.com/lyric/25306933/Queen/Dont+Stop+Me+Now',\n",
    "     'https://www.lyrics.com/lyric/31781320/Eric+Clapton/Tears+In+Heaven']\n",
    "\n",
    "\n",
    "lyrics = [scrape_lyrics(link) for link in links]\n",
    "\n",
    "artists = ['JustinBieber', 'EdSheeran', 'TaylorSwift', 'Kygo', 'Lauv', 'Coldplay', 'OneDirection','Bahari','Rozes','Maroon5', 'Queen', 'EricClapton']\n",
    "\n",
    "#fun fact: queen dont stop me now is apparently the happiest song, and eric clapton is supposedly a sad song\n",
    "# https://www.indy100.com/article/dont-stop-me-now-is-the-happiest-song-in-the-world-according-to-a-neuroscientist-7318321\n",
    "#but there's more to the what affects the sentiment of the song, not just the lyrics, e.g. tempo\n",
    "\n",
    "df = pd.DataFrame({'Lyrics':lyrics}, index=artists)\n",
    "\n",
    "pol = lambda x: TextBlob(x).sentiment.polarity\n",
    "sub = lambda x: TextBlob(x).sentiment.subjectivity\n",
    "df['polarity'] = df['Lyrics'].apply(pol)\n",
    "df['subjectivity'] = df['Lyrics'].apply(sub)\n",
    "\n",
    "plt.rcParams['figure.figsize'] = [10, 8]\n",
    "\n",
    "for artist in df.index:\n",
    "    x = df.polarity.loc[artist]\n",
    "    y = df.subjectivity.loc[artist]\n",
    "    plt.scatter(x, y, color='green')\n",
    "    plt.text(x+.001, y+.001, artist, fontsize=10)\n",
    "    plt.xlim(-.7, .7) \n",
    "    plt.ylim(0,1) \n",
    "    \n",
    "plt.title('Sentiment Analysis', fontsize=20)\n",
    "plt.xlabel('<-- Negative ---------- Positive -->', fontsize=15)\n",
    "plt.ylabel('<-- Facts -------- Opinions -->', fontsize=15)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
